## sử dụng mô hình bert
language: vi
pipeline:
   - name: WhitespaceTokenizer
   - name: LanguageModelFeaturizer
    # Name of the language model to use
     model_name: "bert"
    # Pre-Trained weights to be loaded
     model_weights: "rasa/LaBSE"
   - name: "SklearnIntentClassifier"
    # Specifies the list of regularization values to
    # cross-validate over for C-SVM.
    # This is used with the ``kernel`` hyperparameter in GridSearchCV.
     C: [1, 2, 5, 10, 20, 100]
    # Specifies the kernel to use with C-SVM.
    # This is used with the ``C`` hyperparameter in GridSearchCV.
     kernels: ["linear"]
    # Gamma parameter of the C-SVM.
     "gamma": [0.1]
    # We try to find a good number of cross folds to use during
    # intent training, this specifies the max number of folds.
     "max_cross_validation_folds": 5
    # Scoring function used for evaluating the hyper parameters.
    # This can be a name or a function.
     "scoring_function": "f1_weighted"
   - name: DIETClassifier
     epochs: 100
     constrain_similarities: true
     intent_classification: False
policies:
# # No configuration for policies was provided. The following default policies were used to train your model.
# # If you'd like to customize them, uncomment and adjust the policies.
# # See https://rasa.com/docs/rasa/policies for more information.
#   - name: MemoizationPolicy
#   - name: RulePolicy
#   - name: UnexpecTEDIntentPolicy
#     max_history: 5
#     epochs: 100
#   - name: TEDPolicy
#     max_history: 5
#     epochs: 100
#     constrain_similarities: true
